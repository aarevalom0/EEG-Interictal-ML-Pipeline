{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMaLyv5t2VkV"
      },
      "source": [
        "# Detection of interictal periods in EEG signals using machine learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3NbVY4N2YxO"
      },
      "source": [
        "## loading and preprocessing of databases\n",
        "\n",
        "This notebook is used to load and preprocess the data of Bonn and Delhi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZT1CjZR3C1o"
      },
      "source": [
        "## Prepare the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45DEbLAj3GHK"
      },
      "source": [
        "### Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3s1mF8fI2YXg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za22s73S4J5u"
      },
      "source": [
        "### Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nweIvOcA4Qm6"
      },
      "outputs": [],
      "source": [
        "PATH_DATASET = \"../datasets\"\n",
        "PATH_SCRIPTS = \"../scripts\"\n",
        "PATH_RESULTS = \"../results\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fFFmLRh3bbV"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mEQrx6hp2BfC"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from scipy.io import loadmat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZOlYfAw3ht4"
      },
      "source": [
        "## Loading datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8Sb93Acz3hT3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_data(path):\n",
        "    \"\"\"\n",
        "    Extract signals of the Bonn and Delhi datasets.\n",
        "\n",
        "    Args:\n",
        "      path: The path to the zip file.\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "      extract_path = os.path.dirname(path)\n",
        "      zip_ref.extractall(extract_path)\n",
        "    dataset={}\n",
        "    extract_bonn_data(dataset)\n",
        "    extract_delhi_data(dataset)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def extract_bonn_data(dataset):\n",
        "    \"\"\"\n",
        "    Extract signals of the Bonn dataset.\n",
        "\n",
        "    Args:\n",
        "      None\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "    \"\"\"\n",
        "    bonn_path = Path(PATH_DATASET) / \"Bonn\"\n",
        "    labels = [\"F\", \"N\", \"O\", \"S\", \"Z\"]\n",
        "    for lbl in labels:\n",
        "        folder = bonn_path / lbl\n",
        "        txt_files = sorted(\n",
        "            list(folder.glob(f\"{lbl}[0-9][0-9][0-9].txt\")) +\n",
        "            list(folder.glob(f\"{lbl}[0-9][0-9][0-9].TXT\"))\n",
        "        )\n",
        "        if lbl not in dataset:\n",
        "            dataset[lbl] = []\n",
        "        for f in txt_files:\n",
        "            try:\n",
        "                # Each .txt contains only numbers (a single column) ──> 1‑D np.ndarray\n",
        "                data = np.loadtxt(f, dtype=float)  # shape: (n_samples,)\n",
        "                dataset[lbl].append(np.asarray(data).squeeze())\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {f.name}: {e}\")\n",
        "\n",
        "\n",
        "def extract_delhi_data(dataset):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    delhi_path = Path(PATH_DATASET) / \"Delhi\"\n",
        "    labels = [\"interictal\", \"preictal\", \"ictal\"]\n",
        "    for lbl in labels:\n",
        "        folder = delhi_path / lbl\n",
        "        mat_files = sorted(folder.glob(f\"{lbl}*.mat\"))\n",
        "        if lbl not in dataset:\n",
        "            dataset[lbl] = []\n",
        "        for f in mat_files:\n",
        "            try:\n",
        "                data = loadmat(f)\n",
        "                dataset[lbl].append(np.asarray(data[lbl]).squeeze())\n",
        "            except Exception as e:\n",
        "                print(f\"  Error reading {f.name}: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYzx_s9l5H9b",
        "outputId": "bfa9eff9-f016-4871-b550-d789068022ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F: 200\n",
            "N: 200\n",
            "O: 200\n",
            "S: 200\n",
            "Z: 200\n",
            "interictal: 50\n",
            "preictal: 50\n",
            "ictal: 50\n"
          ]
        }
      ],
      "source": [
        "raw_path = PATH_DATASET +\"/Raw_data.zip\"\n",
        "\n",
        "dataset= extract_data(raw_path)\n",
        "\n",
        "for key, value in dataset.items():\n",
        "    print(f\"{key}: {len(value)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
